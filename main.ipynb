{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting drivers embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import model_wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = False\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using CUDA...\")\n",
    "    cuda = True\n",
    "\n",
    "gpu = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data file path \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={'Engine_coolant_temperature.1':'transmission_oil_temperature'}, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop([\"Time(s)\", \"Class\", \"PathOrder\"], axis=1)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data[data.columns]  = scaler.fit_transform(data[data.columns])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_features = data.iloc[:, 0:51].values\n",
    "m_labels = data.iloc[:, 52].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(m_features, m_labels, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training data shape : ', X_train.shape, y_train.shape)\n",
    "\n",
    "print('Testing data shape : ', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of outputs :  10\n",
      "Output classes :  ['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J']\n"
     ]
    }
   ],
   "source": [
    "classes = np.unique(y_train)\n",
    "nClasses = len(classes)\n",
    "print('Total number of outputs : ', nClasses)\n",
    "print('Output classes : ', classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "y_train[:, ] = labelencoder_X_1.fit_transform(y_train[:, ])\n",
    "y_test[:, ] = labelencoder_X_1.fit_transform(y_test[:, ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.asarray(y_train).astype('float32')\n",
    "y_test =  np.asarray(y_test).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#added for a test\n",
    "#X_train = np.transpose(np.array(X_train))[2].reshape(1, 1, -1)\n",
    "#X_test= np.transpose(np.array(X_test))[2].reshape(1, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 51, 1)\n",
    "X_test = X_test.reshape(-1, 51, 1)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to True to train a new model\n",
    "training = False\n",
    "\n",
    "# Prefix to path to the saved model\n",
    "model = 'model path'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"batch_size\":10 ,\n",
    "    \"channels\": 30,\n",
    "    \"compared_length\": None,\n",
    "    \"depth\": 10,\n",
    "    \"nb_steps\": 500,\n",
    "    \"in_channels\": 51,\n",
    "    \"kernel_size\": 3,\n",
    "    \"penalty\": None,\n",
    "    \"early_stopping\": None,\n",
    "    \"lr\": 0.001,\n",
    "    \"nb_random_samples\": 10,\n",
    "    \"negative_penalty\": 1,\n",
    "    \"out_channels\": 160,\n",
    "    \"out_channels\": 64,\n",
    "    \"reduced_size\": 80,\n",
    "    \"cuda\": cuda,\n",
    "    \"gpu\": gpu\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_yearly = model_wrappers.CausalCNNEncoderClassifier()\n",
    "encoder_yearly.set_params(**hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if training:\n",
    "    encoder_yearly.fit_encoder(X_train, save_memory=True, verbose=True)\n",
    "    encoder_yearly.save_encoder(model)\n",
    "else:\n",
    "    encoder_yearly.load_encoder(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set true to compute the representations\n",
    "\n",
    "compute_representations = False\n",
    "storage_train_day = 'train representation path '\n",
    "storage_test_day = 'test representation path'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_representations:\n",
    "    train_features_day = encoder_yearly.encode_window(X_train, 1)\n",
    "    np.save(storage_train_day, train_features_day)\n",
    "    test_features_day = encoder_yearly.encode_window(X_test, 1)\n",
    "    np.save(storage_test_day, test_features_day)\n",
    "else:\n",
    "    train_features_day = np.load(storage_train_day)\n",
    "    test_features_day = np.load(storage_test_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_day.shape, test_features_day.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_day =train_features_day.reshape(-1,160)\n",
    "#train_features_day =train_features_day.reshape(-1, 64)\n",
    "test_features_day = test_features_day.reshape(-1,160)\n",
    "#test_features_day = test_features_day.reshape(-1, 64)\n",
    "train_features_day.shape, test_features_day.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(train_features_day, y_train)\n",
    "valid_prediction = svc.predict(test_features_day)\n",
    "print(\"validation accuracy : \", accuracy_score(y_test, valid_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 51)\n",
    "X_test = X_test.reshape(-1, 51)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "valid_prediction = svc.predict(X_test)\n",
    "print(\"validation accuracy : \", accuracy_score(y_test, valid_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scikitplot as skplt\n",
    "#Normalized confusion matrix for the K-NN model\n",
    "\n",
    "skplt.metrics.plot_confusion_matrix(y_test, valid_prediction, normalize=True, cmap='GnBu')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"/Users/mozhi/Desktop/X_train.npy\", X_train)\n",
    "#np.save(\"/Users/mozhi/Desktop/X_test.npy\", X_test)\n",
    "#np.save(\"/Users/mozhi/Desktop/y_test.npy\", y_test)\n",
    "#np.save(\"/Users/mozhi/Desktop/y_train.npy\", y_train)\n",
    "#np.save(\"/Users/mozhi/Desktop/result.npy\", valid_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=True,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, valid_prediction)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "#plt.figure()\n",
    "#plot_confusion_matrix(cnf_matrix, classes=classes,title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=classes, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rand= np.random.choice(test_features_day, 1000, replace=False)\n",
    "\n",
    "idx = np.random.randint(test_features_day.shape[0], size=20000)\n",
    "rand = test_features_day[idx, :]\n",
    "\n",
    "truth = y_test[idx,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "\n",
    "s= TSNE(n_components=2, perplexity=150, random_state=0, n_iter=3000)\n",
    "tdata= s.fit_transform(rand)\n",
    "\n",
    "tdata= np.vstack((tdata.T, truth)).T\n",
    "tdf2 = pd.DataFrame(data=tdata, columns = (\"dim1\",\"dim2\",'label'))\n",
    "\n",
    "sns.FacetGrid(tdf2, hue= 'label', height=6).map(plt.scatter,\"dim1\",\"dim2\").add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
